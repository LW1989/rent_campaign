name: Nightly Tests

on:
  schedule:
    # Run every night at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual triggering
    inputs:
      test_scope:
        description: 'Test scope to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - performance
          - slow
          - memory

env:
  PYTHONPATH: .

jobs:
  # Comprehensive slow tests
  slow-tests:
    name: Slow Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    if: github.event.inputs.test_scope == 'all' || github.event.inputs.test_scope == 'slow' || github.event_name == 'schedule'
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.9", "3.11"]  # Test oldest and newest supported versions
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: requirements.txt
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y gdal-bin libgdal-dev libspatialindex-dev
        # Install additional tools for detailed testing
        sudo apt-get install -y valgrind htop
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install memory-profiler  # For memory testing
    
    - name: Create test data directory
      run: |
        mkdir -p test_data_large
        echo "Created directory for large test datasets"
    
    - name: Run slow tests with extended timeout
      timeout-minutes: 60
      run: |
        pytest -xvs -m "slow" \
               --tb=long \
               --durations=0 \
               --maxfail=3 \
               --timeout=1800 \
               --cov=src \
               --cov-report=xml
    
    - name: Upload slow test coverage
      if: matrix.python-version == '3.11'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: slow-tests
        name: slow-tests-coverage

  # Comprehensive performance testing
  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.event.inputs.test_scope == 'all' || github.event.inputs.test_scope == 'performance' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y gdal-bin libgdal-dev libspatialindex-dev
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-benchmark
    
    - name: System info
      run: |
        echo "System Information:"
        uname -a
        python --version
        pip list | grep -E "(numpy|pandas|geopandas|xarray|scipy)"
        echo "Memory: $(free -h | grep Mem | awk '{print $2}')"
        echo "CPU: $(nproc) cores"
    
    - name: Run performance benchmarks
      run: |
        pytest -xvs -m "performance" \
               --tb=short \
               --durations=0 \
               --benchmark-json=nightly_benchmarks.json \
               --benchmark-sort=mean \
               --benchmark-verbose
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: nightly-performance-results
        path: nightly_benchmarks.json
    
    - name: Performance regression check
      run: |
        python -c "
        import json
        import sys
        
        # Load benchmark results
        try:
            with open('nightly_benchmarks.json', 'r') as f:
                results = json.load(f)
            
            # Check for any tests that took longer than expected
            slow_tests = []
            for test in results.get('benchmarks', []):
                mean_time = test['stats']['mean']
                test_name = test['name']
                
                # Define expected maximum times (in seconds)
                max_times = {
                    'small': 5.0,
                    'medium': 30.0,
                    'large': 120.0,
                }
                
                # Determine expected time based on test name
                expected_max = 60.0  # Default
                for size, max_time in max_times.items():
                    if size in test_name.lower():
                        expected_max = max_time
                        break
                
                if mean_time > expected_max:
                    slow_tests.append((test_name, mean_time, expected_max))
            
            if slow_tests:
                print('⚠️ Performance regressions detected:')
                for test_name, actual, expected in slow_tests:
                    print(f'  {test_name}: {actual:.2f}s (expected < {expected:.2f}s)')
                sys.exit(1)
            else:
                print('✅ All performance tests within expected bounds')
                
        except Exception as e:
            print(f'Could not analyze benchmark results: {e}')
            # Don't fail the workflow for analysis issues
        "

  # Memory usage and leak detection
  memory-tests:
    name: Memory Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_scope == 'all' || github.event.inputs.test_scope == 'memory' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y gdal-bin libgdal-dev libspatialindex-dev
        sudo apt-get install -y valgrind
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install memory-profiler psutil
    
    - name: Memory baseline measurement
      run: |
        python -c "
        import psutil
        import gc
        gc.collect()
        process = psutil.Process()
        baseline_memory = process.memory_info().rss / 1024 / 1024
        print(f'Baseline memory usage: {baseline_memory:.1f} MB')
        
        # Store baseline for later comparison
        with open('memory_baseline.txt', 'w') as f:
            f.write(str(baseline_memory))
        "
    
    - name: Run memory tests
      run: |
        pytest -xvs -m "memory" \
               --tb=short \
               --maxfail=3 || true  # Don't fail on memory test issues
    
    - name: Memory leak detection test
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        import gc
        import psutil
        from tests.utils.factories import RentDataFactory
        from src.functions import detect_wucher_miete
        
        # Read baseline
        with open('memory_baseline.txt', 'r') as f:
            baseline_memory = float(f.read().strip())
        
        process = psutil.Process()
        
        print('Running memory leak detection...')
        initial_memory = process.memory_info().rss / 1024 / 1024
        
        # Run the same operation multiple times
        for i in range(10):
            test_data = RentDataFactory.create_realistic_rent_sample(n_points=500)
            result = detect_wucher_miete(test_data, min_neighbors=5)
            
            # Clean up explicitly
            del test_data, result
            
            if i % 3 == 0:
                gc.collect()
        
        final_memory = process.memory_info().rss / 1024 / 1024
        memory_increase = final_memory - initial_memory
        
        print(f'Initial memory: {initial_memory:.1f} MB')
        print(f'Final memory: {final_memory:.1f} MB')
        print(f'Memory increase: {memory_increase:.1f} MB')
        
        # Allow for some memory increase, but flag significant leaks
        if memory_increase > 100:  # More than 100MB increase
            print(f'⚠️ Potential memory leak detected: +{memory_increase:.1f} MB')
            sys.exit(1)
        else:
            print(f'✅ Memory usage acceptable: +{memory_increase:.1f} MB')
        "

  # Stress testing with large datasets
  stress-tests:
    name: Stress Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_scope == 'all' || github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: requirements.txt
    
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y gdal-bin libgdal-dev libspatialindex-dev
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create large test datasets
      run: |
        python -c "
        import sys
        sys.path.insert(0, '.')
        from tests.utils.factories import RentDataFactory
        
        print('Creating large test datasets...')
        
        # Create and save large datasets for stress testing
        sizes = [1000, 5000, 10000]
        
        for size in sizes:
            print(f'Creating dataset with {size} points...')
            large_data = RentDataFactory.create_realistic_rent_sample(
                n_points=size,
                outlier_fraction=0.05
            )
            large_data.to_file(f'test_data_{size}.geojson', driver='GeoJSON')
            print(f'Saved test_data_{size}.geojson ({len(large_data)} records)')
        
        print('Large test datasets created successfully')
        "
    
    - name: Run stress tests
      timeout-minutes: 90
      run: |
        python -c "
        import sys
        import time
        import geopandas as gpd
        sys.path.insert(0, '.')
        from src.functions import detect_wucher_miete
        
        print('Running stress tests on large datasets...')
        
        test_files = ['test_data_1000.geojson', 'test_data_5000.geojson', 'test_data_10000.geojson']
        
        for test_file in test_files:
            print(f'\\nTesting with {test_file}...')
            
            try:
                # Load data
                gdf = gpd.read_file(test_file)
                print(f'Loaded {len(gdf)} records')
                
                # Run detection with timeout
                start_time = time.time()
                result = detect_wucher_miete(
                    gdf, 
                    threshold=2.0,
                    min_neighbors=10,
                    min_rent_threshold=5.0
                )
                end_time = time.time()
                
                execution_time = end_time - start_time
                print(f'Detected {len(result)} outliers in {execution_time:.2f}s')
                
                # Check for reasonable performance
                max_time = len(gdf) / 100 + 30  # Rough scaling expectation
                if execution_time > max_time:
                    print(f'⚠️ Performance concern: took {execution_time:.2f}s, expected < {max_time:.2f}s')
                else:
                    print(f'✅ Performance acceptable: {execution_time:.2f}s')
                
            except Exception as e:
                print(f'❌ Error processing {test_file}: {e}')
                raise
        
        print('\\n✅ All stress tests completed successfully')
        "

  # Nightly summary
  nightly-summary:
    name: Nightly Test Summary
    runs-on: ubuntu-latest
    needs: [slow-tests, performance-tests, memory-tests, stress-tests]
    if: always()
    
    steps:
    - name: Generate summary
      run: |
        echo "# Nightly Test Summary" > summary.md
        echo "" >> summary.md
        echo "**Test Results:**" >> summary.md
        echo "- Slow Tests: ${{ needs.slow-tests.result }}" >> summary.md
        echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> summary.md
        echo "- Memory Tests: ${{ needs.memory-tests.result }}" >> summary.md
        echo "- Stress Tests: ${{ needs.stress-tests.result }}" >> summary.md
        echo "" >> summary.md
        
        # Determine overall status
        if [[ "${{ needs.slow-tests.result }}" == "success" && \
              "${{ needs.performance-tests.result }}" == "success" && \
              "${{ needs.memory-tests.result }}" == "success" && \
              "${{ needs.stress-tests.result }}" == "success" ]]; then
          echo "**Overall Status:** ✅ All nightly tests passed!" >> summary.md
          echo "The codebase is stable and performant." >> summary.md
        else
          echo "**Overall Status:** ❌ Some nightly tests failed" >> summary.md
          echo "Please check the individual test results for details." >> summary.md
        fi
        
        echo "" >> summary.md
        echo "**Test Run:** $(date)" >> summary.md
        echo "**Branch:** ${{ github.ref }}" >> summary.md
        echo "**Commit:** ${{ github.sha }}" >> summary.md
        
        cat summary.md
    
    - name: Upload summary
      uses: actions/upload-artifact@v3
      with:
        name: nightly-test-summary
        path: summary.md
